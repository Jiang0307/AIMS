{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAUewAJ0RrnV",
        "outputId": "c84bc434-9adc-4600-fc85-2408d8ef472c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)\n",
        "folder = \"drive/MyDrive/AIMS_HW3/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!pip install sklearn-crfsuite\n",
        "!pip freeze > drive/MyDrive/AIMS_HW3/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drfgn2wpRJlp",
        "outputId": "a6387f03-e9c7-4f50-b9b3-bb497e1c90b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (0.8.10)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (4.64.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 14.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.8 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5u7X5QuR_6Rf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn_crfsuite\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite.metrics import flat_classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5avpn8FTRrnV"
      },
      "outputs": [],
      "source": [
        "file_path = f\"{folder}/sample_data.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf8\") as f:\n",
        "    file_text = f.read().encode(\"utf-8\").decode(\"utf-8-sig\")\n",
        "\n",
        "datas = file_text.split(\"\\n\\n--------------------\\n\\n\")[:-1]\n",
        "len(datas)\n",
        "\n",
        "with open(f\"{folder}/processed_data.txt\", \"w\") as f:\n",
        "    for article_id, data in enumerate(datas):\n",
        "        data=data.split(\"\\n\")\n",
        "        content=data[0]\n",
        "        annotations=data[1:]\n",
        "        row = list()\n",
        "        for annot in annotations[1:]:\n",
        "            annot=annot.split(\"\\t\") # annot = article_id, start_pos, end_pos, entity_text, entity_type\n",
        "            row.append(annot)\n",
        "\n",
        "        df = pd.DataFrame(row, columns=data[1].split(\"\\t\"))\n",
        "        position_cols = [\"start_position\", \"end_position\"]\n",
        "        df[position_cols] = df[position_cols].astype(\"int\")\n",
        "\n",
        "        tmp_label_list = np.array([\"O\"] * len(content), dtype=object)\n",
        "        for i in range(len(df)):\n",
        "            start, end, etype = df[\"start_position\"][i], df[\"end_position\"][i], df[\"entity_type\"][i]\n",
        "            tmp_label_list[start] = \"B-\" + str(etype)\n",
        "            tmp_label_list[start+1:end] = \"I-\" + str(etype)\n",
        "\n",
        "        for i, row in enumerate(zip(list(content), tmp_label_list)):\n",
        "            f.write(\" \".join(row) + \"\\n\")\n",
        "        \n",
        "        f.write(\"\\n\")\n",
        "\n",
        "with open(f\"{folder}/processed_data.txt\", \"r\") as in_file:\n",
        "    stripped = (line.strip() for line in in_file)\n",
        "    lines = (line.split(\" \") for line in stripped if line)\n",
        "    with open(f\"{folder}/processed_data.csv\", \"w\",encoding=\"utf-8\") as out_file:\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerow((\"Text\", \"Label\"))\n",
        "        writer.writerows(lines)\n",
        "\n",
        "sentence_id = float(0)\n",
        "with open(f\"{folder}/processed_data.csv\", \"r\") as in_file:\n",
        "    lines = []\n",
        "    for line in in_file:\n",
        "        line = line.strip().split(\",\")\n",
        "        line.append( str(sentence_id) )\n",
        "        if (\"。\" in line) or (\"？\" in line) or (\"！\" in line):\n",
        "            sentence_id += float(1)\n",
        "        lines.append(line)\n",
        "    lines.pop(0)\n",
        "    # write sentence_idx to csv\n",
        "    with open(f\"{folder}/processed_data.csv\", \"w+\",encoding=\"utf-8\") as out_file:\n",
        "        writer = csv.writer(out_file)\n",
        "        writer.writerow((\"Text\", \"Label\",\"sentence_idx\"))\n",
        "        writer.writerows(lines)\n",
        "\n",
        "# file_path = f\"{folder}/processed_data.csv\"\n",
        "# df = pd.read_csv(file_path, encoding = \"utf8\")\n",
        "# df = df.reindex(columns=[\"sentence_idx\",\"Text\",\"Label\"])\n",
        "# data = df[[\"sentence_idx\",\"Text\",\"Label\"]]\n",
        "# data = df[df[\"sentence_idx\"].notnull()]\n",
        "# data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6GMS2hCoRrnW"
      },
      "outputs": [],
      "source": [
        "def CRF(x_train, y_train, x_test, y_test):\n",
        "    # Doc: https://sklearn-crfsuite.readthedocs.io/en/latest/api.html#module-sklearn_crfsuite\n",
        "    crf = sklearn_crfsuite.CRF(algorithm=\"lbfgs\", c1=0.01, c2=0.1, max_iterations=300, min_freq=3, all_possible_transitions=True, verbose=2)\n",
        "    crf.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = crf.predict(x_test)\n",
        "    y_pred_mar = crf.predict_marginals(x_test)\n",
        "\n",
        "    labels = list(crf.classes_)\n",
        "    labels.remove(\"O\")\n",
        "    f1score = metrics.flat_f1_score(y_test, y_pred, average=\"weighted\", labels=labels)\n",
        "    sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
        "\n",
        "    return y_pred, y_pred_mar, f1score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tHtTSi_8RrnW"
      },
      "outputs": [],
      "source": [
        "# Load pretrained word vectors\n",
        "# Get a dict of tokens (key) and their pretrained word vectors (value)\n",
        "# Pre-trained word2vec CBOW word vector: https://fgc.stpi.narl.org.tw/activity/videoDetail/4b1141305ddf5522015de5479f4701b1\n",
        "# Pre-trained fastText word embeddings: https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "dim = 0\n",
        "word_vecs= {}\n",
        "# Open pretrained word vector file\n",
        "# with open(f\"{folder}/cna.cbow.cwe_p.tar_g.512d.0.txt\") as f:\n",
        "with open(f\"{folder}/cc.zh.300.vec\") as f:\n",
        "    for line in f:\n",
        "        tokens = line.strip().split()\n",
        "\n",
        "        # there 2 integers in the first line: vocabulary_size, word_vector_dim\n",
        "        if len(tokens) == 2:\n",
        "            dim = int(tokens[1])\n",
        "            continue\n",
        "    \n",
        "        word = tokens[0] \n",
        "        vec = np.array([ float(t) for t in tokens[1:] ])\n",
        "        word_vecs[word] = vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ey0U_XhpRrnW",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f137b19-6cb4-4d2b-db02-37c5a6bc9511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary_size: 2000000\n",
            "word_vector_dim: (300,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"vocabulary_size: {len(word_vecs)}\")\n",
        "print(f\"word_vector_dim: {vec.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ySlER2ErRrnW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def make_dataset(data_path):\n",
        "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = f.readlines() #.encode(\"utf-8\").decode(\"utf-8-sig\")\n",
        "    data_list, data_list_tmp = list(), list()\n",
        "    article_id_list = list()\n",
        "    idx = 0\n",
        "    for row in data:\n",
        "        data_tuple = tuple()\n",
        "        if row == \"\\n\":\n",
        "            article_id_list.append(idx)\n",
        "            idx+=1\n",
        "            data_list.append(data_list_tmp)\n",
        "            data_list_tmp = []\n",
        "        else:\n",
        "            row = row.strip(\"\\n\").split(\" \")\n",
        "            data_tuple = (row[0], row[1])\n",
        "            data_list_tmp.append(data_tuple)\n",
        "    if len(data_list_tmp) != 0:\n",
        "        data_list.append(data_list_tmp)\n",
        "    \n",
        "    # Here we random split data into training dataset and testing dataset\n",
        "    # But you should take `development data` or `test data` as testing data\n",
        "    # At that time, you could just delete this line, \n",
        "    # nd generate data_list of `train data` and data_list of `development/test data` by this function\n",
        "    traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list=train_test_split(data_list,article_id_list,test_size=0.33,random_state=42)\n",
        "    \n",
        "    return data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T3P8vbYGRrnX"
      },
      "outputs": [],
      "source": [
        "# look up word vectors\n",
        "# turn each word into its pretrained word vector\n",
        "# return a list of word vectors corresponding to each token in train.data\n",
        "def build_word_vectors(data_list, embedding_dict):\n",
        "    embedding_list = list()\n",
        "\n",
        "    # No Match Word (unknown word) Vector in Embedding\n",
        "    unk_vector = np.random.rand(*(list(embedding_dict.values())[0].shape))\n",
        "\n",
        "    for idx_list in range(len(data_list)):\n",
        "        embedding_list_tmp = list()\n",
        "        for idx_tuple in range(len(data_list[idx_list])):\n",
        "            key = data_list[idx_list][idx_tuple][0] # token\n",
        "\n",
        "            if key in embedding_dict:\n",
        "                value = embedding_dict[key]\n",
        "            else:\n",
        "                value = unk_vector\n",
        "            embedding_list_tmp.append(value)\n",
        "        embedding_list.append(embedding_list_tmp)\n",
        "        \n",
        "    return embedding_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qzmKa42yRrnX"
      },
      "outputs": [],
      "source": [
        "# Input features: pretrained word vectors of each token\n",
        "# Return a list of feature dicts, each feature dict corresponding to each token\n",
        "def make_features(embed_list):\n",
        "    feature_list = list()\n",
        "    for idx_list in range(len(embed_list)):\n",
        "        feature_list_tmp = list()\n",
        "        for idx_tuple in range(len(embed_list[idx_list])):\n",
        "            feature_dict = dict()\n",
        "            for idx_vec in range(len(embed_list[idx_list][idx_tuple])):\n",
        "                feature_dict[\"dim_\" + str(idx_vec+1)] = embed_list[idx_list][idx_tuple][idx_vec]\n",
        "            feature_list_tmp.append(feature_dict)\n",
        "        feature_list.append(feature_list_tmp)\n",
        "\n",
        "    return feature_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dNa4fSkYRrnX"
      },
      "outputs": [],
      "source": [
        "# Get the labels of each tokens in train.data\n",
        "# Return a list of lists of labels\n",
        "def process_labels(data_list):\n",
        "    label_list = list()\n",
        "    for idx_list in range(len(data_list)):\n",
        "        label_list_tmp = list()\n",
        "        for idx_tuple in range(len(data_list[idx_list])):\n",
        "            label_list_tmp.append(data_list[idx_list][idx_tuple][1])\n",
        "        label_list.append(label_list_tmp)\n",
        "        \n",
        "    return label_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdoz84b0RrnX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e_uGdFy3RrnX"
      },
      "outputs": [],
      "source": [
        "data_list, traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list = make_dataset(f\"{folder}/processed_data.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BDc_mtuXRrnX"
      },
      "outputs": [],
      "source": [
        "# Load Word Embedding\n",
        "trainembed_list = build_word_vectors(traindata_list, word_vecs)\n",
        "testembed_list = build_word_vectors(testdata_list, word_vecs)\n",
        "\n",
        "# CRF - Train Data (Augmentation Data)\n",
        "x_train = make_features(trainembed_list)\n",
        "y_train = process_labels(traindata_list)\n",
        "\n",
        "# CRF - Test Data (Golden Standard)\n",
        "x_test = make_features(testembed_list)\n",
        "y_test = process_labels(testdata_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hbhes9eBRrnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9921142-c25e-4b99-a126-829e1581f568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 17/17 [00:03<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 3.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 639\n",
            "Seconds required: 0.691\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.010000\n",
            "c2: 0.100000\n",
            "num_memories: 6\n",
            "max_iterations: 300\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.36  loss=36160.39 active=639   feature_norm=1.00\n",
            "Iter 2   time=0.19  loss=17409.24 active=635   feature_norm=14.41\n",
            "Iter 3   time=0.18  loss=16698.49 active=538   feature_norm=13.93\n",
            "Iter 4   time=1.52  loss=6498.85  active=417   feature_norm=6.25\n",
            "Iter 5   time=0.37  loss=5025.94  active=416   feature_norm=6.32\n",
            "Iter 6   time=0.36  loss=2579.79  active=568   feature_norm=7.24\n",
            "Iter 7   time=0.89  loss=2359.17  active=623   feature_norm=7.17\n",
            "Iter 8   time=0.62  loss=2329.00  active=625   feature_norm=6.73\n",
            "Iter 9   time=0.64  loss=1972.55  active=630   feature_norm=7.09\n",
            "Iter 10  time=0.13  loss=1886.92  active=627   feature_norm=7.27\n",
            "Iter 11  time=0.26  loss=1826.17  active=620   feature_norm=7.72\n",
            "Iter 12  time=0.13  loss=1813.45  active=618   feature_norm=7.75\n",
            "Iter 13  time=0.12  loss=1743.85  active=627   feature_norm=8.46\n",
            "Iter 14  time=0.13  loss=1676.72  active=592   feature_norm=8.54\n",
            "Iter 15  time=0.12  loss=1612.95  active=621   feature_norm=8.80\n",
            "Iter 16  time=0.25  loss=1538.81  active=618   feature_norm=9.72\n",
            "Iter 17  time=0.25  loss=1481.37  active=632   feature_norm=10.30\n",
            "Iter 18  time=0.14  loss=1454.46  active=632   feature_norm=10.70\n",
            "Iter 19  time=0.13  loss=1393.25  active=635   feature_norm=11.23\n",
            "Iter 20  time=0.12  loss=1354.84  active=638   feature_norm=11.33\n",
            "Iter 21  time=0.12  loss=1261.58  active=628   feature_norm=12.20\n",
            "Iter 22  time=0.26  loss=1223.54  active=632   feature_norm=12.85\n",
            "Iter 23  time=0.13  loss=1207.63  active=632   feature_norm=13.41\n",
            "Iter 24  time=0.13  loss=1155.71  active=633   feature_norm=14.25\n",
            "Iter 25  time=0.13  loss=1113.45  active=636   feature_norm=14.65\n",
            "Iter 26  time=0.13  loss=1082.86  active=633   feature_norm=15.32\n",
            "Iter 27  time=0.12  loss=1015.67  active=631   feature_norm=16.02\n",
            "Iter 28  time=0.26  loss=981.58   active=635   feature_norm=17.03\n",
            "Iter 29  time=0.25  loss=941.62   active=636   feature_norm=17.50\n",
            "Iter 30  time=0.27  loss=917.37   active=637   feature_norm=18.29\n",
            "Iter 31  time=0.13  loss=893.64   active=631   feature_norm=19.12\n",
            "Iter 32  time=0.13  loss=863.31   active=633   feature_norm=20.37\n",
            "Iter 33  time=0.13  loss=831.59   active=633   feature_norm=20.71\n",
            "Iter 34  time=0.13  loss=814.70   active=637   feature_norm=21.61\n",
            "Iter 35  time=0.13  loss=797.10   active=633   feature_norm=22.16\n",
            "Iter 36  time=0.13  loss=782.57   active=632   feature_norm=23.22\n",
            "Iter 37  time=0.13  loss=764.89   active=634   feature_norm=23.59\n",
            "Iter 38  time=0.14  loss=750.88   active=631   feature_norm=24.34\n",
            "Iter 39  time=0.13  loss=739.52   active=629   feature_norm=25.11\n",
            "Iter 40  time=0.12  loss=731.72   active=632   feature_norm=26.90\n",
            "Iter 41  time=0.13  loss=708.12   active=636   feature_norm=27.16\n",
            "Iter 42  time=0.12  loss=701.01   active=635   feature_norm=28.21\n",
            "Iter 43  time=0.13  loss=691.68   active=632   feature_norm=28.47\n",
            "Iter 44  time=0.13  loss=685.86   active=634   feature_norm=29.27\n",
            "Iter 45  time=0.12  loss=678.91   active=637   feature_norm=29.50\n",
            "Iter 46  time=0.13  loss=673.98   active=636   feature_norm=30.18\n",
            "Iter 47  time=0.12  loss=668.80   active=631   feature_norm=30.36\n",
            "Iter 48  time=0.13  loss=664.84   active=632   feature_norm=31.09\n",
            "Iter 49  time=0.13  loss=659.20   active=634   feature_norm=31.28\n",
            "Iter 50  time=0.13  loss=654.42   active=636   feature_norm=31.76\n",
            "Iter 51  time=0.12  loss=649.84   active=635   feature_norm=31.95\n",
            "Iter 52  time=0.13  loss=644.58   active=634   feature_norm=32.48\n",
            "Iter 53  time=0.13  loss=638.88   active=636   feature_norm=32.73\n",
            "Iter 54  time=0.13  loss=634.84   active=638   feature_norm=33.44\n",
            "Iter 55  time=0.13  loss=629.19   active=635   feature_norm=33.66\n",
            "Iter 56  time=0.12  loss=624.01   active=634   feature_norm=34.17\n",
            "Iter 57  time=0.12  loss=620.79   active=637   feature_norm=34.37\n",
            "Iter 58  time=0.13  loss=616.62   active=636   feature_norm=34.76\n",
            "Iter 59  time=0.13  loss=613.08   active=634   feature_norm=34.99\n",
            "Iter 60  time=0.13  loss=609.86   active=632   feature_norm=35.42\n",
            "Iter 61  time=0.12  loss=606.71   active=633   feature_norm=35.65\n",
            "Iter 62  time=0.14  loss=603.47   active=632   feature_norm=36.03\n",
            "Iter 63  time=0.12  loss=600.59   active=636   feature_norm=36.19\n",
            "Iter 64  time=0.12  loss=598.89   active=636   feature_norm=36.47\n",
            "Iter 65  time=0.12  loss=596.47   active=634   feature_norm=36.61\n",
            "Iter 66  time=0.12  loss=594.76   active=637   feature_norm=36.83\n",
            "Iter 67  time=0.12  loss=592.66   active=634   feature_norm=36.93\n",
            "Iter 68  time=0.13  loss=590.96   active=637   feature_norm=37.12\n",
            "Iter 69  time=0.13  loss=588.94   active=637   feature_norm=37.23\n",
            "Iter 70  time=0.12  loss=587.44   active=637   feature_norm=37.50\n",
            "Iter 71  time=0.12  loss=585.27   active=638   feature_norm=37.59\n",
            "Iter 72  time=0.13  loss=583.94   active=639   feature_norm=37.81\n",
            "Iter 73  time=0.12  loss=582.10   active=637   feature_norm=37.89\n",
            "Iter 74  time=0.12  loss=580.82   active=637   feature_norm=38.04\n",
            "Iter 75  time=0.13  loss=579.21   active=637   feature_norm=38.13\n",
            "Iter 76  time=0.12  loss=577.47   active=636   feature_norm=38.28\n",
            "Iter 77  time=0.12  loss=576.15   active=636   feature_norm=38.34\n",
            "Iter 78  time=0.13  loss=574.32   active=637   feature_norm=38.51\n",
            "Iter 79  time=0.14  loss=572.69   active=638   feature_norm=38.55\n",
            "Iter 80  time=0.13  loss=570.85   active=638   feature_norm=38.63\n",
            "Iter 81  time=0.12  loss=568.86   active=639   feature_norm=38.64\n",
            "Iter 82  time=0.12  loss=567.10   active=634   feature_norm=38.74\n",
            "Iter 83  time=0.12  loss=565.08   active=631   feature_norm=38.76\n",
            "Iter 84  time=0.13  loss=563.55   active=635   feature_norm=38.83\n",
            "Iter 85  time=0.13  loss=562.37   active=637   feature_norm=38.82\n",
            "Iter 86  time=0.13  loss=561.34   active=636   feature_norm=38.86\n",
            "Iter 87  time=0.14  loss=560.33   active=637   feature_norm=38.83\n",
            "Iter 88  time=0.12  loss=559.09   active=637   feature_norm=38.85\n",
            "Iter 89  time=0.12  loss=558.31   active=636   feature_norm=38.81\n",
            "Iter 90  time=0.12  loss=557.20   active=636   feature_norm=38.82\n",
            "Iter 91  time=0.14  loss=556.29   active=637   feature_norm=38.78\n",
            "Iter 92  time=0.13  loss=555.40   active=637   feature_norm=38.76\n",
            "Iter 93  time=0.13  loss=553.95   active=634   feature_norm=38.68\n",
            "Iter 94  time=0.12  loss=552.43   active=635   feature_norm=38.63\n",
            "Iter 95  time=0.12  loss=550.94   active=637   feature_norm=38.52\n",
            "Iter 96  time=0.12  loss=550.01   active=634   feature_norm=38.55\n",
            "Iter 97  time=0.12  loss=549.11   active=634   feature_norm=38.49\n",
            "Iter 98  time=0.13  loss=547.96   active=632   feature_norm=38.46\n",
            "Iter 99  time=0.12  loss=546.39   active=634   feature_norm=38.37\n",
            "Iter 100 time=0.12  loss=545.20   active=636   feature_norm=38.31\n",
            "Iter 101 time=0.13  loss=544.62   active=636   feature_norm=38.23\n",
            "Iter 102 time=0.12  loss=543.93   active=636   feature_norm=38.24\n",
            "Iter 103 time=0.13  loss=543.05   active=636   feature_norm=38.17\n",
            "Iter 104 time=0.12  loss=542.42   active=637   feature_norm=38.17\n",
            "Iter 105 time=0.12  loss=541.55   active=636   feature_norm=38.12\n",
            "Iter 106 time=0.12  loss=541.04   active=635   feature_norm=38.12\n",
            "Iter 107 time=0.13  loss=540.03   active=636   feature_norm=38.04\n",
            "Iter 108 time=0.12  loss=539.49   active=637   feature_norm=38.06\n",
            "Iter 109 time=0.13  loss=538.92   active=638   feature_norm=38.02\n",
            "Iter 110 time=0.13  loss=538.43   active=638   feature_norm=38.00\n",
            "Iter 111 time=0.13  loss=537.53   active=634   feature_norm=37.95\n",
            "Iter 112 time=0.24  loss=536.78   active=636   feature_norm=37.91\n",
            "Iter 113 time=0.25  loss=536.10   active=634   feature_norm=37.86\n",
            "Iter 114 time=0.25  loss=535.57   active=637   feature_norm=37.83\n",
            "Iter 115 time=0.25  loss=535.16   active=639   feature_norm=37.80\n",
            "Iter 116 time=0.25  loss=534.74   active=637   feature_norm=37.78\n",
            "Iter 117 time=0.25  loss=534.42   active=637   feature_norm=37.75\n",
            "Iter 118 time=0.13  loss=534.33   active=637   feature_norm=37.71\n",
            "Iter 119 time=0.13  loss=533.69   active=638   feature_norm=37.64\n",
            "Iter 120 time=0.13  loss=533.27   active=638   feature_norm=37.65\n",
            "Iter 121 time=0.13  loss=532.86   active=638   feature_norm=37.60\n",
            "Iter 122 time=0.12  loss=532.56   active=638   feature_norm=37.60\n",
            "Iter 123 time=0.13  loss=532.23   active=639   feature_norm=37.56\n",
            "Iter 124 time=0.12  loss=531.75   active=637   feature_norm=37.55\n",
            "Iter 125 time=0.25  loss=531.38   active=637   feature_norm=37.51\n",
            "Iter 126 time=0.13  loss=531.36   active=635   feature_norm=37.50\n",
            "Iter 127 time=0.13  loss=530.67   active=635   feature_norm=37.42\n",
            "Iter 128 time=0.14  loss=530.31   active=637   feature_norm=37.42\n",
            "Iter 129 time=0.12  loss=530.01   active=638   feature_norm=37.38\n",
            "Iter 130 time=0.12  loss=529.67   active=637   feature_norm=37.38\n",
            "Iter 131 time=0.13  loss=529.57   active=635   feature_norm=37.30\n",
            "Iter 132 time=0.12  loss=529.27   active=637   feature_norm=37.34\n",
            "Iter 133 time=0.12  loss=528.70   active=638   feature_norm=37.26\n",
            "Iter 134 time=0.13  loss=528.42   active=638   feature_norm=37.27\n",
            "Iter 135 time=0.12  loss=528.03   active=639   feature_norm=37.23\n",
            "Iter 136 time=0.13  loss=527.91   active=637   feature_norm=37.24\n",
            "Iter 137 time=0.12  loss=527.49   active=638   feature_norm=37.20\n",
            "Iter 138 time=0.12  loss=527.26   active=638   feature_norm=37.20\n",
            "Iter 139 time=0.13  loss=527.21   active=637   feature_norm=37.15\n",
            "Iter 140 time=0.12  loss=526.89   active=638   feature_norm=37.17\n",
            "Iter 141 time=0.13  loss=526.66   active=638   feature_norm=37.11\n",
            "Iter 142 time=0.13  loss=526.39   active=638   feature_norm=37.13\n",
            "Iter 143 time=0.12  loss=526.11   active=639   feature_norm=37.09\n",
            "Iter 144 time=0.12  loss=525.95   active=638   feature_norm=37.10\n",
            "Iter 145 time=0.13  loss=525.68   active=639   feature_norm=37.07\n",
            "Iter 146 time=0.12  loss=525.50   active=639   feature_norm=37.07\n",
            "Iter 147 time=0.12  loss=525.27   active=638   feature_norm=37.03\n",
            "Iter 148 time=0.12  loss=525.13   active=637   feature_norm=37.05\n",
            "Iter 149 time=0.12  loss=524.88   active=637   feature_norm=37.01\n",
            "Iter 150 time=0.12  loss=524.77   active=636   feature_norm=37.03\n",
            "Iter 151 time=0.12  loss=524.49   active=637   feature_norm=36.99\n",
            "Iter 152 time=0.13  loss=524.41   active=637   feature_norm=37.01\n",
            "Iter 153 time=0.13  loss=524.10   active=636   feature_norm=36.98\n",
            "Iter 154 time=0.13  loss=524.07   active=636   feature_norm=37.00\n",
            "Iter 155 time=0.12  loss=523.74   active=637   feature_norm=36.97\n",
            "Iter 156 time=0.25  loss=523.54   active=638   feature_norm=36.98\n",
            "Iter 157 time=0.12  loss=523.27   active=639   feature_norm=36.95\n",
            "Iter 158 time=0.25  loss=523.09   active=639   feature_norm=36.96\n",
            "Iter 159 time=0.26  loss=522.92   active=638   feature_norm=36.94\n",
            "Iter 160 time=0.25  loss=522.72   active=637   feature_norm=36.95\n",
            "Iter 161 time=0.25  loss=522.56   active=637   feature_norm=36.93\n",
            "Iter 162 time=0.25  loss=522.40   active=637   feature_norm=36.94\n",
            "Iter 163 time=0.25  loss=522.24   active=638   feature_norm=36.93\n",
            "Iter 164 time=0.26  loss=522.10   active=638   feature_norm=36.94\n",
            "Iter 165 time=0.25  loss=521.95   active=638   feature_norm=36.93\n",
            "Iter 166 time=0.25  loss=521.81   active=639   feature_norm=36.95\n",
            "Iter 167 time=0.25  loss=521.69   active=639   feature_norm=36.93\n",
            "Iter 168 time=0.25  loss=521.49   active=639   feature_norm=36.94\n",
            "Iter 169 time=0.25  loss=521.38   active=639   feature_norm=36.93\n",
            "Iter 170 time=0.25  loss=521.21   active=639   feature_norm=36.95\n",
            "Iter 171 time=0.25  loss=521.10   active=638   feature_norm=36.94\n",
            "Iter 172 time=0.25  loss=520.94   active=639   feature_norm=36.96\n",
            "Iter 173 time=0.25  loss=520.81   active=639   feature_norm=36.95\n",
            "Iter 174 time=0.25  loss=520.69   active=639   feature_norm=36.97\n",
            "Iter 175 time=0.25  loss=520.59   active=638   feature_norm=36.96\n",
            "Iter 176 time=0.25  loss=520.42   active=639   feature_norm=36.98\n",
            "Iter 177 time=0.24  loss=520.33   active=639   feature_norm=36.97\n",
            "Iter 178 time=0.25  loss=520.18   active=638   feature_norm=36.99\n",
            "Iter 179 time=0.12  loss=520.16   active=638   feature_norm=36.97\n",
            "Iter 180 time=0.13  loss=519.85   active=637   feature_norm=37.00\n",
            "Iter 181 time=0.26  loss=519.70   active=637   feature_norm=36.99\n",
            "Iter 182 time=0.26  loss=519.59   active=638   feature_norm=37.00\n",
            "Iter 183 time=0.26  loss=519.48   active=637   feature_norm=37.00\n",
            "Iter 184 time=0.25  loss=519.36   active=636   feature_norm=37.01\n",
            "Iter 185 time=0.26  loss=519.28   active=637   feature_norm=37.00\n",
            "Iter 186 time=0.26  loss=519.10   active=638   feature_norm=37.02\n",
            "Iter 187 time=0.26  loss=519.03   active=639   feature_norm=37.01\n",
            "Iter 188 time=0.25  loss=518.89   active=639   feature_norm=37.03\n",
            "Iter 189 time=0.26  loss=518.81   active=639   feature_norm=37.02\n",
            "Iter 190 time=0.26  loss=518.68   active=639   feature_norm=37.03\n",
            "Iter 191 time=0.13  loss=518.59   active=638   feature_norm=37.02\n",
            "Iter 192 time=0.12  loss=518.54   active=638   feature_norm=37.05\n",
            "Iter 193 time=0.13  loss=518.38   active=637   feature_norm=37.03\n",
            "Iter 194 time=0.13  loss=518.23   active=636   feature_norm=37.06\n",
            "Iter 195 time=0.13  loss=518.06   active=638   feature_norm=37.06\n",
            "Iter 196 time=0.26  loss=517.96   active=639   feature_norm=37.06\n",
            "Iter 197 time=0.13  loss=517.80   active=639   feature_norm=37.06\n",
            "Iter 198 time=0.26  loss=517.66   active=638   feature_norm=37.07\n",
            "Iter 199 time=0.38  loss=517.51   active=638   feature_norm=37.06\n",
            "Iter 200 time=0.37  loss=517.46   active=638   feature_norm=37.07\n",
            "Iter 201 time=0.38  loss=517.33   active=637   feature_norm=37.07\n",
            "Iter 202 time=0.38  loss=517.29   active=638   feature_norm=37.07\n",
            "Iter 203 time=0.37  loss=517.16   active=639   feature_norm=37.07\n",
            "Iter 204 time=0.26  loss=517.15   active=638   feature_norm=37.08\n",
            "Iter 205 time=0.14  loss=517.15   active=638   feature_norm=37.08\n",
            "Iter 206 time=0.13  loss=516.93   active=639   feature_norm=37.08\n",
            "Iter 207 time=0.12  loss=516.84   active=639   feature_norm=37.09\n",
            "Iter 208 time=0.13  loss=516.73   active=638   feature_norm=37.09\n",
            "Iter 209 time=0.13  loss=516.65   active=639   feature_norm=37.09\n",
            "Iter 210 time=0.13  loss=516.59   active=639   feature_norm=37.10\n",
            "Iter 211 time=0.13  loss=516.49   active=638   feature_norm=37.10\n",
            "Iter 212 time=0.13  loss=516.46   active=638   feature_norm=37.10\n",
            "Iter 213 time=0.13  loss=516.38   active=638   feature_norm=37.10\n",
            "Iter 214 time=0.12  loss=516.33   active=638   feature_norm=37.11\n",
            "Iter 215 time=0.13  loss=516.25   active=638   feature_norm=37.11\n",
            "Iter 216 time=0.13  loss=516.18   active=637   feature_norm=37.11\n",
            "Iter 217 time=0.13  loss=516.11   active=637   feature_norm=37.11\n",
            "Iter 218 time=0.13  loss=516.02   active=637   feature_norm=37.12\n",
            "Iter 219 time=0.13  loss=515.97   active=638   feature_norm=37.12\n",
            "Iter 220 time=0.12  loss=515.88   active=638   feature_norm=37.13\n",
            "Iter 221 time=0.14  loss=515.83   active=638   feature_norm=37.12\n",
            "Iter 222 time=0.14  loss=515.74   active=638   feature_norm=37.13\n",
            "Iter 223 time=0.13  loss=515.72   active=639   feature_norm=37.13\n",
            "Iter 224 time=0.13  loss=515.61   active=638   feature_norm=37.14\n",
            "Iter 225 time=0.13  loss=515.56   active=639   feature_norm=37.14\n",
            "Iter 226 time=0.12  loss=515.48   active=639   feature_norm=37.14\n",
            "Iter 227 time=0.12  loss=515.45   active=639   feature_norm=37.14\n",
            "Iter 228 time=0.13  loss=515.33   active=639   feature_norm=37.15\n",
            "Iter 229 time=0.12  loss=515.33   active=639   feature_norm=37.14\n",
            "Iter 230 time=0.12  loss=515.20   active=638   feature_norm=37.15\n",
            "Iter 231 time=0.25  loss=515.13   active=638   feature_norm=37.15\n",
            "Iter 232 time=0.13  loss=514.98   active=639   feature_norm=37.14\n",
            "Iter 233 time=0.12  loss=514.29   active=638   feature_norm=37.08\n",
            "Iter 234 time=0.51  loss=514.26   active=639   feature_norm=37.08\n",
            "Iter 235 time=0.37  loss=514.24   active=639   feature_norm=37.07\n",
            "Iter 236 time=0.39  loss=514.10   active=639   feature_norm=37.07\n",
            "Iter 237 time=0.39  loss=514.06   active=639   feature_norm=37.05\n",
            "Iter 238 time=0.37  loss=513.95   active=639   feature_norm=37.05\n",
            "Iter 239 time=0.37  loss=513.91   active=639   feature_norm=37.04\n",
            "Iter 240 time=0.12  loss=513.84   active=639   feature_norm=37.04\n",
            "Iter 241 time=0.13  loss=513.75   active=639   feature_norm=37.03\n",
            "Iter 242 time=0.13  loss=513.69   active=639   feature_norm=37.03\n",
            "Iter 243 time=0.13  loss=513.64   active=639   feature_norm=37.02\n",
            "Iter 244 time=0.13  loss=513.55   active=639   feature_norm=37.03\n",
            "Iter 245 time=0.12  loss=513.53   active=638   feature_norm=37.01\n",
            "Iter 246 time=0.12  loss=513.42   active=638   feature_norm=37.02\n",
            "Iter 247 time=0.13  loss=513.41   active=639   feature_norm=37.01\n",
            "Iter 248 time=0.12  loss=513.27   active=639   feature_norm=37.01\n",
            "Iter 249 time=0.26  loss=513.21   active=639   feature_norm=37.00\n",
            "Iter 250 time=0.25  loss=513.16   active=639   feature_norm=37.00\n",
            "Iter 251 time=0.25  loss=513.13   active=638   feature_norm=37.00\n",
            "Iter 252 time=0.26  loss=513.06   active=639   feature_norm=37.00\n",
            "Iter 253 time=0.25  loss=513.01   active=639   feature_norm=36.99\n",
            "Iter 254 time=0.24  loss=512.93   active=639   feature_norm=36.99\n",
            "Iter 255 time=0.24  loss=512.88   active=639   feature_norm=36.98\n",
            "Iter 256 time=0.25  loss=512.80   active=639   feature_norm=36.99\n",
            "Iter 257 time=0.25  loss=512.75   active=639   feature_norm=36.98\n",
            "Iter 258 time=0.25  loss=512.68   active=639   feature_norm=36.98\n",
            "Iter 259 time=0.26  loss=512.64   active=639   feature_norm=36.97\n",
            "Iter 260 time=0.26  loss=512.57   active=639   feature_norm=36.97\n",
            "Iter 261 time=0.25  loss=512.53   active=638   feature_norm=36.96\n",
            "Iter 262 time=0.25  loss=512.46   active=638   feature_norm=36.96\n",
            "Iter 263 time=0.25  loss=512.42   active=637   feature_norm=36.95\n",
            "Iter 264 time=0.25  loss=512.35   active=638   feature_norm=36.95\n",
            "Iter 265 time=0.25  loss=512.32   active=638   feature_norm=36.94\n",
            "Iter 266 time=0.25  loss=512.25   active=638   feature_norm=36.94\n",
            "Iter 267 time=0.25  loss=512.21   active=637   feature_norm=36.93\n",
            "Iter 268 time=0.27  loss=512.16   active=637   feature_norm=36.93\n",
            "Iter 269 time=0.25  loss=512.14   active=639   feature_norm=36.92\n",
            "Iter 270 time=0.26  loss=512.07   active=638   feature_norm=36.92\n",
            "Iter 271 time=0.26  loss=512.05   active=639   feature_norm=36.91\n",
            "Iter 272 time=0.25  loss=511.99   active=638   feature_norm=36.92\n",
            "Iter 273 time=0.27  loss=511.97   active=637   feature_norm=36.91\n",
            "Iter 274 time=0.26  loss=511.92   active=637   feature_norm=36.91\n",
            "Iter 275 time=0.13  loss=511.83   active=638   feature_norm=36.89\n",
            "Iter 276 time=0.25  loss=511.81   active=639   feature_norm=36.89\n",
            "Iter 277 time=0.26  loss=511.79   active=637   feature_norm=36.88\n",
            "Iter 278 time=0.26  loss=511.69   active=637   feature_norm=36.87\n",
            "Iter 279 time=0.26  loss=511.67   active=639   feature_norm=36.87\n",
            "Iter 280 time=0.25  loss=511.60   active=639   feature_norm=36.86\n",
            "Iter 281 time=0.25  loss=511.59   active=638   feature_norm=36.86\n",
            "Iter 282 time=0.13  loss=511.54   active=638   feature_norm=36.86\n",
            "Iter 283 time=0.13  loss=511.53   active=639   feature_norm=36.85\n",
            "Iter 284 time=0.13  loss=511.48   active=639   feature_norm=36.85\n",
            "Iter 285 time=0.13  loss=511.47   active=639   feature_norm=36.84\n",
            "Iter 286 time=0.13  loss=511.41   active=638   feature_norm=36.84\n",
            "Iter 287 time=0.14  loss=511.40   active=638   feature_norm=36.83\n",
            "Iter 288 time=0.12  loss=511.35   active=639   feature_norm=36.83\n",
            "Iter 289 time=0.13  loss=511.33   active=638   feature_norm=36.82\n",
            "Iter 290 time=0.13  loss=511.27   active=638   feature_norm=36.82\n",
            "Iter 291 time=0.13  loss=511.26   active=638   feature_norm=36.82\n",
            "Iter 292 time=0.13  loss=511.19   active=638   feature_norm=36.81\n",
            "Iter 293 time=0.13  loss=511.19   active=639   feature_norm=36.81\n",
            "Iter 294 time=0.13  loss=511.12   active=639   feature_norm=36.81\n",
            "Iter 295 time=0.27  loss=511.08   active=639   feature_norm=36.80\n",
            "Iter 296 time=0.14  loss=510.99   active=639   feature_norm=36.80\n",
            "Iter 297 time=0.27  loss=510.96   active=639   feature_norm=36.78\n",
            "Iter 298 time=0.26  loss=510.92   active=637   feature_norm=36.78\n",
            "Iter 299 time=0.25  loss=510.82   active=637   feature_norm=36.77\n",
            "Iter 300 time=0.26  loss=510.73   active=638   feature_norm=36.77\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 55.929\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 638 (639)\n",
            "Number of active attributes: 237 (300)\n",
            "Number of active labels: 11 (11)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred, y_pred_mar, f1score = CRF(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H02UitQBRrnX",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a34911-96d0-467a-ec6e-0a23f0c6b8db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6216282465488363"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "f1score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QC66RB5tRrnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8186e275-5dc1-4cd4-8afa-7659ea7c5ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+----------------+----------------+---------------+\n",
            "|   article_id |   start_position |   end_position | entity_text    | entity_type   |\n",
            "|--------------+------------------+----------------+----------------+---------------|\n",
            "|            8 |               10 |             12 | 38             | med_exam      |\n",
            "|            8 |              189 |            193 | 二十分鐘       | time          |\n",
            "|            8 |              293 |            295 | 五年           | time          |\n",
            "|            8 |              519 |            521 | 吩咐           | time          |\n",
            "|            8 |              540 |            544 | 兩個禮拜       | time          |\n",
            "|            8 |              858 |            862 | 前天下午       | time          |\n",
            "|            8 |             1354 |           1356 | 娜美           | name          |\n",
            "|            8 |             1549 |           1551 | 五天           | time          |\n",
            "|            8 |             1622 |           1627 | 五天禮拜三     | time          |\n",
            "|            8 |             1939 |           1941 | 恍惚           | time          |\n",
            "|            8 |             1992 |           1997 | 禮拜三下午     | time          |\n",
            "|            8 |             2279 |           2282 | 185            | med_exam      |\n",
            "|            8 |             2377 |           2380 | 185            | med_exam      |\n",
            "|            8 |             2387 |           2390 | 185            | med_exam      |\n",
            "|            8 |             2560 |           2563 | 兩個月         | time          |\n",
            "|            8 |             2671 |           2674 | 155            | med_exam      |\n",
            "|            8 |             2679 |           2682 | 155            | med_exam      |\n",
            "|            8 |             2696 |           2699 | 155            | med_exam      |\n",
            "|           16 |               60 |             66 | 九、十點晚上   | time          |\n",
            "|           16 |              122 |            124 | 三年           | time          |\n",
            "|           16 |              130 |            132 | 三年           | time          |\n",
            "|           16 |              247 |            249 | 三年           | time          |\n",
            "|           16 |              592 |            595 | 5個月          | time          |\n",
            "|           16 |              980 |            982 | 宴客           | name          |\n",
            "|            0 |               55 |             57 | 68             | med_exam      |\n",
            "|            0 |               66 |             68 | 68             | med_exam      |\n",
            "|            0 |              435 |            437 | 歐洲           | location      |\n",
            "|            0 |             1264 |           1271 | 10.78公分      | med_exam      |\n",
            "|            0 |             2304 |           2307 | 海洛英         | name          |\n",
            "|            0 |             2523 |           2526 | 法馬上         | time          |\n",
            "|            0 |             2575 |           2578 | 四五天         | time          |\n",
            "|            0 |             2604 |           2609 | 3月18號        | time          |\n",
            "|            0 |             2630 |           2635 | 3月24日        | time          |\n",
            "|            0 |             2650 |           2654 | 3月24          | time          |\n",
            "|            0 |             2663 |           2670 | 禮拜二到禮拜四 | time          |\n",
            "|            0 |             2692 |           2697 | 3月31日        | time          |\n",
            "|           24 |               48 |             51 | 三個月         | time          |\n",
            "|           24 |               53 |             56 | 七公斤         | med_exam      |\n",
            "|           24 |              113 |            115 | 三年           | time          |\n",
            "|           24 |              141 |            143 | 三年           | time          |\n",
            "|           24 |              495 |            498 | 法來箝         | time          |\n",
            "|           24 |              536 |            538 | 來箝           | time          |\n",
            "|           24 |              547 |            549 | 來箝           | time          |\n",
            "|           24 |             1018 |           1023 | 5月28日        | time          |\n",
            "|           24 |             1196 |           1200 | 300塊          | money         |\n",
            "|           24 |             1246 |           1250 | 230塊          | money         |\n",
            "|           24 |             1408 |           1410 | 明明           | time          |\n",
            "|           24 |             1858 |           1861 | 二個月         | time          |\n",
            "|           24 |             1869 |           1872 | 二個月         | time          |\n",
            "|           24 |             1986 |           1989 | 五個月         | time          |\n",
            "|           11 |               18 |             21 | 九千七         | money         |\n",
            "|           11 |               83 |             86 | 九千七         | money         |\n",
            "|           11 |              107 |            110 | 8.5            | med_exam      |\n",
            "|           11 |              111 |            115 | 12.4           | med_exam      |\n",
            "|           11 |              118 |            121 | 3.6            | med_exam      |\n",
            "|           11 |              135 |            139 | 三個禮拜       | time          |\n",
            "|           11 |              514 |            518 | 三個禮拜       | time          |\n",
            "|           11 |              557 |            561 | 三個禮拜       | time          |\n",
            "|           11 |              569 |            573 | 三個禮拜       | time          |\n",
            "|           11 |              645 |            649 | 三個禮拜       | time          |\n",
            "|           11 |              672 |            676 | 三個禮拜       | time          |\n",
            "|           11 |              693 |            697 | 兩個禮拜       | time          |\n",
            "|           11 |              708 |            713 | 四月二十日     | time          |\n",
            "|           11 |              751 |            755 | 兩個禮拜       | time          |\n",
            "|           11 |              923 |            925 | 小櫻           | name          |\n",
            "|           11 |             1077 |           1080 | 666            | med_exam      |\n",
            "|           11 |             1084 |           1087 | 666            | med_exam      |\n",
            "|           11 |             1094 |           1097 | 098            | med_exam      |\n",
            "|           11 |             1101 |           1104 | 098            | med_exam      |\n",
            "|           11 |             1109 |           1113 | 7403           | med_exam      |\n",
            "|           11 |             1117 |           1121 | 7403           | med_exam      |\n",
            "|           11 |             1125 |           1135 | 6660897403     | med_exam      |\n",
            "|           11 |             1142 |           1148 | 666098         | med_exam      |\n",
            "|           11 |             1152 |           1159 | 0987403        | med_exam      |\n",
            "|            9 |               70 |             74 | 兩千多塊       | money         |\n",
            "|            9 |              184 |            190 | 85.5公斤       | med_exam      |\n",
            "|            9 |              273 |            276 | 泳四天         | time          |\n",
            "|            9 |              290 |            294 | 四十分鐘       | time          |\n",
            "|            9 |              330 |            333 | 490            | med_exam      |\n",
            "|            9 |              489 |            493 | 次亞西吉       | location      |\n",
            "|            9 |              743 |            746 | 374            | med_exam      |\n",
            "|            9 |              763 |            766 | 490            | med_exam      |\n",
            "|            9 |              770 |            773 | 490            | med_exam      |\n",
            "|            9 |              800 |            803 | 390            | med_exam      |\n",
            "|            9 |              834 |            837 | 505            | med_exam      |\n",
            "|           13 |               37 |             39 | 95             | med_exam      |\n",
            "|           13 |               64 |             66 | 95             | med_exam      |\n",
            "|           13 |               74 |             76 | 95             | med_exam      |\n",
            "|           13 |              145 |            150 | 2月20號        | time          |\n",
            "|           13 |              153 |            155 | 78             | med_exam      |\n",
            "|           13 |              394 |            397 | 六個月         | time          |\n",
            "|           13 |              417 |            420 | 24周           | time          |\n",
            "|           13 |              435 |            439 | 500塊          | money         |\n",
            "|           13 |              444 |            448 | 500塊          | money         |\n",
            "|           13 |              550 |            553 | 六個月         | time          |\n",
            "|           13 |              636 |            641 | 4月20號        | time          |\n",
            "|           13 |              662 |            664 | 5月            | time          |\n",
            "|           13 |              671 |            673 | 5月            | time          |\n",
            "|           13 |              678 |            681 | 5月初          | time          |\n",
            "|           13 |              701 |            705 | 兩個禮拜       | time          |\n",
            "|           13 |              721 |            723 | 半月           | time          |\n",
            "|           13 |              731 |            735 | 5月1號         | time          |\n",
            "|           13 |              774 |            776 | 5月            | time          |\n",
            "|           13 |              784 |            788 | 四個禮拜       | time          |\n",
            "|           13 |              793 |            797 | 四個禮拜       | time          |\n",
            "|           13 |              804 |            808 | 4月17          | time          |\n",
            "|           13 |              830 |            834 | 4月17          | time          |\n",
            "|           13 |              891 |            896 | 3月20號        | time          |\n",
            "|           13 |              946 |            950 | 四個禮拜       | time          |\n",
            "|           13 |             1050 |           1055 | 2月20號        | time          |\n",
            "|           13 |             1081 |           1083 | 37             | med_exam      |\n",
            "|            1 |              235 |            237 | 中午           | time          |\n",
            "|            1 |              254 |            256 | 中午           | time          |\n",
            "|            1 |              802 |            805 | 三個月         | time          |\n",
            "|            1 |              904 |            909 | 五十二百分     | money         |\n",
            "|            1 |              915 |            920 | 五十二百分     | money         |\n",
            "|            1 |              933 |            936 | 陳醫師         | name          |\n",
            "|            1 |             1052 |           1055 | 五個月         | time          |\n",
            "|            1 |             1340 |           1344 | 馬馬虎虎       | location      |\n",
            "|            1 |             1349 |           1353 | 馬馬虎虎       | location      |\n",
            "|            1 |             1385 |           1387 | 六年           | time          |\n",
            "|            1 |             1394 |           1396 | 四年           | time          |\n",
            "|            1 |             1404 |           1406 | 四年           | time          |\n",
            "|            1 |             1414 |           1416 | 四年           | time          |\n",
            "|            1 |             2261 |           2263 | 半月           | time          |\n",
            "|            1 |             2295 |           2299 | 兩個禮拜       | time          |\n",
            "|            1 |             2334 |           2338 | 三個禮拜       | time          |\n",
            "|            1 |             2404 |           2407 | 陳醫師         | name          |\n",
            "|           23 |              275 |            278 | 三個月         | time          |\n",
            "|           23 |              339 |            343 | 4月27          | time          |\n",
            "|           23 |              535 |            538 | 三個月         | time          |\n",
            "|           23 |              540 |            543 | 二個月         | time          |\n",
            "|           23 |              556 |            559 | 三個月         | time          |\n",
            "|           23 |              629 |            633 | 8月1號         | time          |\n",
            "|           23 |             1584 |           1588 | 8月21          | time          |\n",
            "|           23 |             1592 |           1596 | 8月2號         | time          |\n",
            "|           23 |             1600 |           1603 | 821            | time          |\n",
            "|           23 |             1642 |           1645 | 821            | time          |\n",
            "+--------------+------------------+----------------+----------------+---------------+\n"
          ]
        }
      ],
      "source": [
        "output=[]\n",
        "header = [\"article_id\",\"start_position\",\"end_position\",\"entity_text\",\"entity_type\"]\n",
        "for test_id in range(len(y_pred)):\n",
        "    pos=0\n",
        "    start_pos=None\n",
        "    end_pos=None\n",
        "    entity_text=None\n",
        "    entity_type=None\n",
        "    for pred_id in range(len(y_pred[test_id])):\n",
        "        line=[]\n",
        "        if y_pred[test_id][pred_id][0]==\"B\":\n",
        "            start_pos=pos\n",
        "            entity_type=y_pred[test_id][pred_id][2:]\n",
        "        elif start_pos is not None and y_pred[test_id][pred_id][0]==\"I\" and y_pred[test_id][pred_id+1][0]==\"O\":\n",
        "            end_pos=pos\n",
        "            entity_text=\"\".join([testdata_list[test_id][position][0] for position in range(start_pos,end_pos+1)])\n",
        "            line.append(str(testdata_article_id_list[test_id]))\n",
        "            line.append(str(start_pos))\n",
        "            line.append(str(end_pos+1))\n",
        "            line.append(str(entity_text))\n",
        "            line.append(str(entity_type))\n",
        "            output.append(line)\n",
        "        pos+=1\n",
        "\n",
        "output_path=f\"{folder}/output.tsv\"\n",
        "with open(output_path,\"w\",encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(output)\n",
        "\n",
        "\n",
        "print(tabulate(output, headers=header, tablefmt=\"psql\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "file_extension": ".py",
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 (default, Mar 17 2022, 10:20:15) [MSC v.1900 64 bit (AMD64)]"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "vscode": {
      "interpreter": {
        "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}